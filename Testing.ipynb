{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "from models import TCNmodel\n",
    "import numpy as np\n",
    "from random import randrange\n",
    "from skimage.io import imread_collection\n",
    "from IPython.core.display import HTML\n",
    "from torch import nn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "train_sample,frame = torch.load('dataset_train.pt')\n",
    "#train_sample,frame = torch.load('dataset_test.pt')\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = TCNmodel()\n",
    "# net=net.to('cuda')\n",
    "# test = train_sample.reshape(-1,3,360,640)\n",
    "# inputs = test[0:41,:,:,:] \n",
    "# inputs.shape\n",
    "# inputs = inputs.to('cuda')\n",
    "# with torch.no_grad():\n",
    "#     outputs = net(inputs)\n",
    "    \n",
    "# torch.cuda.empty_cache()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_dataset(data,frame, net,device):\n",
    "    net = net.to(device)\n",
    "    data = data.reshape(-1,3,360,640)\n",
    "    i = 0 \n",
    "    final_output = []\n",
    "    F,C,W,H = data.shape\n",
    "    with torch.no_grad():\n",
    "        for j in range(frame.shape[0]):\n",
    "            f = frame[j]+i\n",
    "            inputs = data[i:f,:,:,:]\n",
    "            data_loader = torch.utils.data.DataLoader(inputs, batch_size = 12, shuffle = False)\n",
    "            i = f \n",
    "            outputs =torch.tensor([]) \n",
    "            for j, subdata in enumerate(data_loader):\n",
    "                subdata= subdata.to(device)\n",
    "                suboutputs = net(subdata)\n",
    "                outputs = torch.cat((outputs,suboutputs.cpu()),0)\n",
    "            final_output.append(outputs)\n",
    "    torch.cuda.empty_cache()\n",
    "    return final_output\n",
    "\n",
    "#looks for nearest neighbour\n",
    "def cosine(outputs):\n",
    "    list_frames_outputs = []\n",
    "    for i in range(len(outputs)):\n",
    "        output = outputs[i].cpu().detach().numpy() \n",
    "        #cosine = cosine_similarity(output)\n",
    "        cosine = euclidean_distances(output)\n",
    "        prev_frame = 0\n",
    "        list = []\n",
    "        list.append(prev_frame)\n",
    "        for i in range(len(output-1)):\n",
    "            cosine[i][i] = 0\n",
    "            cosine[:,prev_frame] = 0\n",
    "            test = np.nanargmax(cosine[i])\n",
    "            prev_frame = test\n",
    "            list.append(test)\n",
    "        list_frames_outputs.append(list)\n",
    "    return list_frames_outputs\n",
    "\n",
    "# searches for frames between -1 and 1 frame away > so for frame 3 the next frame can be 4 or 2 \n",
    "def test_accuracy(list,tolerance):\n",
    "    accuracy = []\n",
    "    for j in range(len(list)):\n",
    "        acc = 0\n",
    "        for i in range(len(list[j])-1):\n",
    "            if list[j][i+1] in range(list[j][i]-tolerance-1, list[j][i]+tolerance+1):\n",
    "                acc += 1 \n",
    "        accuracy.append((acc / (len(list[j])-1))*100)\n",
    "    return accuracy\n",
    "\n",
    "def test(outputs):\n",
    "    list_frames_outputs = cosine(outputs)\n",
    "    test_accuracy_list = test_accuracy(list_frames_outputs, 1)\n",
    "    av_accuracy = np.mean(test_accuracy_list)\n",
    "    return list_frames_outputs , test_accuracy_list, av_accuracy\n",
    "\n",
    "import cv2\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from matplotlib import animation\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def create_animation(images, interval_ms=100, **fig_kwargs):\n",
    "\n",
    "    # use larger plot by default\n",
    "    if \"figsize\" not in fig_kwargs:\n",
    "        fig_kwargs[\"figsize\"] = (13, 9)\n",
    "\n",
    "    fig, ax = plt.subplots(**fig_kwargs)\n",
    "    fig.tight_layout()\n",
    "    ax.axis(\"off\")\n",
    "    im = ax.imshow(images[0][:, :, ::-1])\n",
    "    plt.close()  # this is required to not display the generated image\n",
    "\n",
    "    def init():\n",
    "        im.set_data(images[0][:, :, ::-1])  # ::-1: BGR --> RGB\n",
    "\n",
    "    def animate(i):\n",
    "        image = images[i]\n",
    "        if image is not None:\n",
    "            im.set_data(image[:, :, ::-1])\n",
    "        return im\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, animate, init_func=init, frames=len(images), interval=interval_ms)\n",
    "\n",
    "    # disable warning for video creation (anim.to_*())\n",
    "    import logging\n",
    "\n",
    "    logging.getLogger(\"matplotlib.animation\").disabled = True\n",
    "\n",
    "    # from IPython.core.display import HTML\n",
    "    # use HTML(anim.to_html5_video()) to show within jupyter notebook as video\n",
    "    # or HTML(anim.to_jshtml()) to show within jupyter notebook as interactive widget\n",
    "    return anim\n",
    "\n",
    "\n",
    "def draw_bbox_to_image(image, bbox, color=(0, 255, 0), thickness=5):\n",
    "    corner_coords = bbox.get_bbox_corners_vis()\n",
    "    image = cv2.rectangle(image, corner_coords[:2], corner_coords[-2:], color, thickness)\n",
    "    return image\n",
    "\n",
    "\n",
    "def showimage(a):\n",
    "    \"\"\"Show an image below the current jupyter notebook cell.\n",
    "    Expects gray or bgr input (opencv2 default)\"\"\"\n",
    "    # bgr -> rgb\n",
    "    if len(a.shape) > 2 and a.shape[2] == 3:\n",
    "        a = a[..., ::-1]  # bgr -> rgb\n",
    "    image = PIL.Image.fromarray(a)\n",
    "    IPython.display.display(image)  # display in cell output\n",
    "\n",
    "\n",
    "# https://colorbrewer2.org/#type=qualitative&scheme=Paired&n=12\n",
    "colors_qualitative = np.array(\n",
    "    [\n",
    "        [166, 206, 227],\n",
    "        [31, 120, 180],\n",
    "        [178, 223, 138],\n",
    "        [51, 160, 44],\n",
    "        [251, 154, 153],\n",
    "        [227, 26, 28],\n",
    "        [253, 191, 111],\n",
    "        [255, 127, 0],\n",
    "        [202, 178, 214],\n",
    "        [106, 61, 154],\n",
    "        [255, 255, 153],\n",
    "        [177, 89, 40],\n",
    "    ]\n",
    ")\n",
    "\n",
    "# rgb representation for k3d\n",
    "colors_qualitative_k3d = np.dot(colors_qualitative, np.asarray([2 ** 16, 2 ** 8, 2 ** 0])).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     PATH = 'C:/Users/maxwa/Documents/TCN_self_supervised_learning/SaveModel_' +str(9*i) + '.pth'\n",
    "#     print(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Think/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.20737721764115\n",
      "Wall time: 6.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# for i in range(5):\n",
    "#     PATH = './checkpoint/SaveModel_' +str(159) + '.pth'\n",
    "#     print(PATH)\n",
    "PATH = './checkpoints/SaveModel_590.pth'\n",
    "model = TCNmodel()\n",
    "model.load_state_dict(torch.load(PATH)['net'])\n",
    "model.eval()\n",
    "device = 'cuda'\n",
    "outputs = output_dataset(train_sample,frame,model,device)\n",
    "list_frames_outputs, accuracy,av_accuracy = test(outputs)\n",
    "print(av_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print((list_frames_outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.193009476072206\n",
      "0\n",
      "42\n",
      "[0, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "There are only 0 images in the collection",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-86c042fd3672>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_frames_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist_frames_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0manim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_animation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minterval_ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skimage\\io\\collection.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_imgnum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m             \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skimage\\io\\collection.py\u001b[0m in \u001b[0;36m_check_imgnum\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             raise IndexError(\"There are only %s images in the collection\"\n\u001b[0m\u001b[0;32m    322\u001b[0m                              % num)\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: There are only 0 images in the collection"
     ]
    }
   ],
   "source": [
    "print(av_accuracy)\n",
    "col_dir_test = 'frames/train/1/*.jpg'\n",
    "#creating a collection with the available images\n",
    "img_test = imread_collection(col_dir_test)\n",
    "print(len(img_test))\n",
    "print(len(list_frames_outputs[0]))\n",
    "print(list_frames_outputs[0])\n",
    "images = []\n",
    "for i in range(len(list_frames_outputs[0])):\n",
    "    index = list_frames_outputs[0][i]\n",
    "    images.append(img_test[index])\n",
    "    \n",
    "anim = create_animation(images,interval_ms=100)\n",
    "video = anim.to_html5_video()\n",
    "HTML(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dir_test = 'frames/test/*.jpg'\n",
    "#creating a collection with the available images\n",
    "img_test = imread_collection(col_dir_test)\n",
    "img_test_1 = img_test[:46]\n",
    "print(len(img_test_1))\n",
    "print(img_test_1[0].shape)\n",
    "test = np.zeros([46,1080,1920,3])\n",
    "for i in range(46):\n",
    "    test[i,:,:,:] = img_test_1[i]\n",
    "    \n",
    "print(test.shape)\n",
    "test = np.reshape(test,(46,1080*1920*3))\n",
    "print(test.shape)\n",
    "#list_frames_outputs, accuracy,av_accuracy  = test(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

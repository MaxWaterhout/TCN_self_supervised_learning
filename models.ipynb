{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGPGh5Gfa6Db"
   },
   "source": [
    "Define TimeContrastiveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6lNZuLD0bBrU"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "class Convblock(nn.Module):\n",
    "    def __init__(self, in_channels,hidden_channels,out_channels):\n",
    "        super(Convblock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, hidden_channels,\n",
    "                               kernel_size=5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(hidden_channels, out_channels,\n",
    "                               kernel_size=5)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # reshape\n",
    "        x = x.view(-1,288,42,77) # x.view(-1,288,35,35) for 299 x 299 else 360 x 640\n",
    "        x = self.conv1(x)\n",
    "        # Activation function\n",
    "        x = self.relu1(x)\n",
    "        # Second convolutional layer\n",
    "        x = self.conv2(x)\n",
    "        # Activation function\n",
    "        x = self.relu2(x)\n",
    "        return x\n",
    "\n",
    "# spatial Softmax and last linear layer\n",
    "class SpatialSoftmax(torch.nn.Module):\n",
    "    def __init__(self, height, width, channel, temperature=None):\n",
    "        super(SpatialSoftmax, self).__init__()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.channel = channel\n",
    "\n",
    "        if temperature:  \n",
    "          self.temperature = torch.ones(1)*temperature   \n",
    "        else:   \n",
    "          self.temperature = nn.Parameter(torch.ones(1))  \n",
    "\n",
    "        pos_x, pos_y = np.meshgrid(\n",
    "                np.linspace(-1., 1., self.height),\n",
    "                np.linspace(-1., 1., self.width)\n",
    "                )\n",
    "        pos_x = torch.from_numpy(pos_x.reshape(self.height*self.width)).float()\n",
    "        pos_y = torch.from_numpy(pos_y.reshape(self.height*self.width)).float()\n",
    "        self.register_buffer('pos_x', pos_x)\n",
    "        self.register_buffer('pos_y', pos_y)\n",
    "        self.linear =nn.Linear(32, 32)\n",
    "\n",
    "    def forward(self, feature):\n",
    "        feature = feature.view(-1,self.height*self.width)\n",
    "\n",
    "        softmax_attention = nn.functional.softmax(feature/self.temperature, dim=-1)\n",
    "        expected_x = torch.sum(self.pos_x*softmax_attention, dim=1, keepdim=True)\n",
    "        expected_y = torch.sum(self.pos_y*softmax_attention, dim=1, keepdim=True)\n",
    "        expected_xy = torch.cat([expected_x, expected_y], 1)\n",
    "        feature_keypoints = expected_xy.view(-1, self.channel*2)\n",
    "        feature_keypoints = self.linear(feature_keypoints)\n",
    "\n",
    "        return feature_keypoints\n",
    "\n",
    "# TCNmodel\n",
    "class TCNmodel(nn.Module):\n",
    "  # input tensor: N x 3 x H(>=299) x W(>=299) \n",
    "  # output tensor: N x 32\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TCNmodel, self).__init__()\n",
    "        self.model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\n",
    "        self.conv2 = Convblock(288,32,16)\n",
    "        self.spmax = SpatialSoftmax(34,69,16,temperature=None) #SpatialSoftmax(27,27,16,temperature=None) for 299 x 299 else for 360 x 640\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.Conv2d_1a_3x3(x)\n",
    "        x = self.model.Conv2d_2a_3x3(x)\n",
    "        x = self.model.Conv2d_2b_3x3(x)\n",
    "        x = self.model.maxpool1(x)\n",
    "\n",
    "        x = self.model.Conv2d_3b_1x1(x)\n",
    "        x = self.model.Conv2d_4a_3x3(x)\n",
    "        x = self.model.maxpool2(x)\n",
    "        x = self.model.Mixed_5b(x)\n",
    "        x = self.model.Mixed_5c(x)\n",
    "        x = self.model.Mixed_5d(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.spmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GoVBKjDihOQI",
    "outputId": "275e1138-0393-4b6b-8de3-97cf293863c9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "# #testing model\n",
    "# model = TCNmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eKmHk0y6iCI9",
    "outputId": "a680e1d3-8eb9-4a46-ab61-d413cb6d6815"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1546, 1213)\n"
     ]
    }
   ],
   "source": [
    "# import urllib\n",
    "# url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "# try: urllib.URLopener().retrieve(url, filename)\n",
    "# except: urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "# # sample execution (requires torchvision)\n",
    "# from PIL import Image\n",
    "# from torchvision import transforms\n",
    "# input_image = Image.open(filename)\n",
    "# preprocess = transforms.Compose([\n",
    "#     transforms.Resize([360,640]),\n",
    "#     #transforms.CenterCrop(299),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "# ])\n",
    "# print(input_image.size)\n",
    "\n",
    "# # input_tensor = preprocess(input_image)\n",
    "# # input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "# # print(input_batch.shape)\n",
    "# # input_batch=torch.cat(10*[input_batch])\n",
    "# # print(input_batch.shape)\n",
    "# # #input_batch = torch.cat((input_batch,input_batch),dim=0)\n",
    "# # # move the input and model to GPU for speed if available\n",
    "# # if torch.cuda.is_available():\n",
    "# #     input_batch = input_batch.to('cuda')\n",
    "# #     model.to('cuda')\n",
    "\n",
    "# # with torch.no_grad():\n",
    "# #   output = model(input_batch)\n",
    "# # # Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
    "# # print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

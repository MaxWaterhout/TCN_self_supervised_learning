{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 421, 3, 360, 640])\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "from models import TCNmodel\n",
    "import numpy as np\n",
    "from random import randrange\n",
    "\n",
    "train_sample,frame = torch.load('dataset.pt')\n",
    "\n",
    "print(train_sample.shape)\n",
    "\n",
    "#data_loader = torch.utils.data.DataLoader(train_sample, batch_size = 1, shuffle = True)\n",
    "# for videos in data_loader:\n",
    "#     print(videos.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n",
      "(41,)\n",
      "(41,)\n",
      "(50,)\n",
      "(91,)\n",
      "(42,)\n",
      "(133,)\n",
      "(35,)\n",
      "(168,)\n",
      "(31,)\n",
      "(199,)\n",
      "(40,)\n",
      "(239,)\n",
      "(37,)\n",
      "(276,)\n",
      "(40,)\n",
      "(316,)\n",
      "(33,)\n",
      "(349,)\n",
      "(42,)\n",
      "(391,)\n",
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "# data=train_sample\n",
    "# N,F,C,W,H = data.shape # F: frame\n",
    "\n",
    "# idx = np.arange(F)\n",
    "# count=0\n",
    "\n",
    "#     # positve & negative\n",
    "# posindex = np.array([])\n",
    "# negindex = np.array([])\n",
    "# for j in range(len(frame)):\n",
    "#     f = frame[j]\n",
    "#     Posidx_j = np.zeros(f)\n",
    "#     Negidx_j = np.zeros(f)\n",
    "#     for i in range(f):\n",
    "#         # pp positve\n",
    "#         pp= randrange(-1,1)\n",
    "#         if pp ==-1:\n",
    "#             Posidx_j[i]=-1\n",
    "#         else:\n",
    "#             Posidx_j[i]=1\n",
    "        \n",
    "#         # pn negative      \n",
    "#         pn = randrange(0,f)\n",
    "#         while pn<=i+2 & pn>=i-2:\n",
    "#             pn=randrange(0,f)\n",
    "#         Negidx_j[i]=pn+count\n",
    "        \n",
    "#     count = count+f\n",
    "         \n",
    "#         # fixed index value at 0 frame and end frame\n",
    "#     Posidx_j[0]=1\n",
    "#     Posidx_j[-1]=-1\n",
    "#     #print(posindex.shape)\n",
    "#     #print(Posidx_j.shape)\n",
    "#     posindex=np.concatenate((posindex,Posidx_j))\n",
    "#     negindex = np.concatenate((negindex,Negidx_j))\n",
    "    \n",
    "# posindex = idx+posindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.   0.   3.   4.   3.   4.   5.   8.   9.  10.   9.  10.  13.  12.\n",
      "  13.  16.  15.  18.  17.  20.  19.  22.  21.  22.  25.  24.  27.  28.\n",
      "  29.  30.  31.  32.  31.  34.  33.  34.  35.  36.  37.  38.  39.  42.\n",
      "  43.  42.  45.  44.  47.  46.  49.  50.  51.  52.  51.  52.  53.  54.\n",
      "  55.  58.  57.  58.  59.  62.  61.  62.  63.  64.  67.  68.  67.  68.\n",
      "  69.  70.  71.  74.  73.  74.  77.  78.  79.  80.  79.  80.  81.  84.\n",
      "  85.  86.  85.  86.  89.  88.  89.  92.  93.  94.  93.  96.  95.  96.\n",
      "  97. 100. 101. 100. 101. 104. 103. 106. 105. 106. 109. 110. 111. 112.\n",
      " 111. 112. 115. 116. 115. 116. 119. 118. 119. 122. 123. 122. 125. 124.\n",
      " 127. 128. 129. 130. 131. 130. 131. 134. 135. 136. 135. 138. 139. 140.\n",
      " 141. 140. 141. 142. 143. 144. 147. 148. 147. 150. 149. 152. 151. 152.\n",
      " 155. 154. 155. 156. 157. 160. 159. 162. 163. 162. 163. 164. 167. 166.\n",
      " 169. 168. 169. 170. 173. 174. 175. 176. 175. 178. 179. 178. 179. 180.\n",
      " 181. 182. 183. 186. 187. 188. 187. 190. 191. 192. 193. 192. 195. 194.\n",
      " 195. 198. 197. 200. 199. 200. 201. 202. 203. 206. 207. 206. 209. 208.\n",
      " 209. 212. 211. 214. 215. 214. 217. 216. 217. 220. 221. 222. 221. 224.\n",
      " 225. 224. 227. 226. 227. 228. 231. 232. 231. 234. 235. 236. 235. 236.\n",
      " 237. 240. 241. 240. 241. 242. 245. 246. 247. 246. 247. 248. 249. 250.\n",
      " 251. 252. 255. 256. 255. 258. 257. 258. 259. 262. 261. 262. 265. 264.\n",
      " 267. 268. 267. 270. 271. 270. 273. 272. 273. 274. 277. 276. 277. 278.\n",
      " 281. 280. 281. 284. 285. 284. 285. 288. 289. 290. 289. 290. 293. 292.\n",
      " 293. 296. 297. 298. 297. 298. 299. 302. 301. 302. 303. 304. 305. 306.\n",
      " 309. 310. 311. 312. 313. 312. 313. 314. 317. 318. 319. 320. 321. 320.\n",
      " 321. 322. 323. 324. 327. 328. 329. 328. 329. 330. 333. 332. 335. 334.\n",
      " 337. 338. 339. 340. 339. 342. 343. 342. 345. 346. 345. 348. 347. 350.\n",
      " 349. 350. 353. 354. 353. 354. 357. 356. 359. 360. 359. 360. 363. 362.\n",
      " 363. 364. 365. 366. 369. 370. 371. 372. 371. 372. 375. 374. 377. 378.\n",
      " 377. 378. 379. 380. 381. 384. 383. 386. 385. 386. 389. 388. 389. 392.\n",
      " 391. 392. 393. 394. 395. 398. 399. 398. 399. 400. 401. 402. 405. 404.\n",
      " 407. 408. 407. 408. 409. 410. 411. 412. 413. 416. 415. 418. 417. 418.\n",
      " 419.]\n",
      "[ 19.  25.   2.  16.  11.   2.  37.  31.   5.   7.  17.  34.  40.  29.\n",
      "  21.  37.  21.  25.   4.  15.  27.  27.  28.  17.  14.   1.  36.  39.\n",
      "  23.  34.  33.   1.   9.   3.  17.  38.   9.   7.   2.   8.  17.  83.\n",
      "  57.  62.  81.  79.  70.  58.  66.  63.  79.  67.  80.  77.  63.  59.\n",
      "  41.  44.  73.  70.  85.  52.  51.  58.  80.  77.  56.  73.  51.  41.\n",
      "  57.  57.  52.  58.  50.  57.  49.  54.  87.  58.  90.  71.  41.  65.\n",
      "  48.  77.  61.  51.  76.  90.  48. 106. 112.  96. 110. 105. 114. 110.\n",
      " 109. 126. 130. 123. 121. 114. 101. 120. 115.  97. 116. 113. 117.  97.\n",
      " 104. 127. 129. 116. 126. 113.  96. 109.  98. 105.  92.  92. 117. 106.\n",
      " 103. 101.  97. 122. 116. 103. 114. 163. 165. 147. 167. 157. 133. 135.\n",
      " 167. 155. 145. 164. 156. 139. 166. 142. 161. 152. 158. 162. 152. 146.\n",
      " 167. 147. 140. 158. 145. 160. 146. 139. 146. 159. 163. 157. 136. 154.\n",
      " 184. 176. 183. 190. 169. 192. 171. 192. 190. 185. 169. 194. 169. 176.\n",
      " 174. 170. 181. 178. 196. 176. 174. 178. 186. 194. 188. 184. 198. 172.\n",
      " 170. 169. 174. 207. 227. 202. 224. 222. 207. 238. 224. 229. 214. 222.\n",
      " 229. 231. 206. 237. 229. 204. 200. 213. 213. 233. 216. 228. 237. 208.\n",
      " 203. 200. 201. 217. 237. 202. 227. 212. 217. 213. 226. 207. 229. 207.\n",
      " 233. 248. 262. 269. 254. 249. 250. 270. 262. 240. 259. 240. 239. 271.\n",
      " 273. 274. 267. 245. 273. 267. 251. 268. 244. 271. 259. 241. 269. 248.\n",
      " 241. 262. 241. 257. 250. 246. 241. 255. 253. 261. 280. 309. 287. 292.\n",
      " 305. 309. 292. 286. 278. 279. 277. 283. 312. 298. 281. 282. 297. 279.\n",
      " 287. 288. 293. 315. 313. 287. 310. 277. 282. 276. 312. 302. 291. 302.\n",
      " 311. 312. 284. 281. 287. 308. 293. 305. 317. 335. 333. 323. 325. 329.\n",
      " 323. 323. 330. 316. 327. 331. 341. 332. 325. 318. 331. 320. 331. 339.\n",
      " 330. 322. 321. 334. 346. 339. 321. 336. 345. 348. 344. 322. 317. 378.\n",
      " 373. 352. 390. 365. 385. 386. 355. 360. 383. 370. 365. 351. 389. 366.\n",
      " 373. 349. 351. 375. 389. 363. 350. 359. 376. 386. 383. 383. 367. 390.\n",
      " 350. 390. 360. 375. 388. 373. 388. 363. 362. 386. 365. 368. 386. 403.\n",
      " 396. 406. 405. 396. 406. 394. 403. 394. 398. 391. 415. 395. 411. 417.\n",
      " 406. 403. 398. 395. 405. 391. 420. 399. 399. 392. 398. 396. 403. 392.\n",
      " 404.]\n"
     ]
    }
   ],
   "source": [
    "# print(posindex)\n",
    "# print(negindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DatasetCon(data,frame):\n",
    "    # construct a F x 3 x C x W x H tensoR\n",
    "    # 0: anchor, 1: positive, 2: negative\n",
    "    N,F,C,W,H = data.shape # F: frame\n",
    "    anchor = data\n",
    "    idx = np.arange(F)\n",
    "    count=0\n",
    "\n",
    "    # positve & negative\n",
    "    posindex = np.array([])\n",
    "    negindex = np.array([])\n",
    "    for j in range(len(frame)):\n",
    "        f = frame[j]\n",
    "        Posidx_j = np.zeros(f)\n",
    "        Negidx_j = np.zeros(f)\n",
    "        for i in range(f):\n",
    "        # pp positve\n",
    "            pp= randrange(-1,1)\n",
    "            if pp ==-1:\n",
    "                Posidx_j[i]=-1\n",
    "            else:\n",
    "                Posidx_j[i]=1\n",
    "        \n",
    "        # pn negative      \n",
    "            pn = randrange(0,f)\n",
    "            while pn<=i+2 & pn>=i-2:\n",
    "                pn=randrange(0,f)\n",
    "            Negidx_j[i]=pn+count\n",
    "        \n",
    "        count = count+f\n",
    "         \n",
    "        # fixed index value at 0 frame and end frame\n",
    "        Posidx_j[0]=1\n",
    "        Posidx_j[-1]=-1\n",
    "        posindex=np.concatenate((posindex,Posidx_j))\n",
    "        negindex = np.concatenate((negindex,Negidx_j))\n",
    "    \n",
    "    posindex = idx+posindex\n",
    "    positive = data[:,posindex,:,:,:]\n",
    "\n",
    "    negative = data[:,negindex,:,:,:]\n",
    "    dataset = torch.cat([anchor,positive,negative])\n",
    "    dataset = dataset.transpose(0,1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([421, 3, 3, 360, 640])\n"
     ]
    }
   ],
   "source": [
    "# dataset = DatasetCon(train_sample,frame)\n",
    "# print(dataset.shape)\n",
    "# # data_loader = torch.utils.data.DataLoader(dataset, batch_size = 4, shuffle = True)\n",
    "# # for videos in data_loader:\n",
    "# #     print(videos.size())\n",
    "# #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=TCNmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     output = model(torch.reshape(videos,[-1,3,360,640]))\n",
    "# # Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output=output.reshape([4,3,-1])\n",
    "# print(output.shape)\n",
    "# anchor = output[:,0,:]\n",
    "# positive = output[:,1,:]\n",
    "# negative = output[:,2,:]\n",
    "# triplet_loss = torch.nn.TripletMarginLoss(margin=0.2, p=2)\n",
    "# # corr=torch.mm(output,output.transpose(0,1))\n",
    "# loss = triplet_loss(anchor, positive, negative)\n",
    "# print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, net, optimizer, criterion,device):\n",
    "    \"\"\"\n",
    "    Trains network for one epoch in batches.\n",
    "\n",
    "    Args:\n",
    "        train_loader: Data loader for training set.\n",
    "        net: Neural network model.\n",
    "        optimizer: Optimizer (e.g. SGD).\n",
    "        criterion: Loss function (e.g. cross-entropy loss).\n",
    "    \"\"\"\n",
    "  \n",
    "    avg_loss = 0\n",
    "    #correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # iterate through batches\n",
    "    for i, data in enumerate(train_loader):\n",
    "        N,P,C,W,H = data.shape\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = data.reshape([-1,C,W,H])\n",
    "        inputs= inputs.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        outputs = outputs.reshape([N,P,-1])\n",
    "        \n",
    "        anchor = outputs[:,0,:]\n",
    "        positive = outputs[:,1,:]\n",
    "        negative = outputs[:,2,:]\n",
    "        \n",
    "        loss = criterion(anchor,positive,negative)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # keep track of loss and accuracy\n",
    "        avg_loss += loss\n",
    "        #print(avg_loss)\n",
    "    return avg_loss/len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Think/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [04:51<04:51, 58.35s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-559ca806b8cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mdata_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# Train on data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;31m#print(train_loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-105-dbec0212ae36>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_loader, net, optimizer, criterion, device)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# get the inputs; data is a list of [inputs, labels]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[1;31m# zero the parameter gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "epochs = 10\n",
    "\n",
    "# Create instance of Network\n",
    "net = TCNmodel()\n",
    "\n",
    "# Create loss function and optimizer\n",
    "criterion = torch.nn.TripletMarginLoss(margin=0.2, p=2)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=5e-1)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#device = 'cpu'\n",
    "net = net.to(device)\n",
    "# print(device)\n",
    "for epoch in tqdm(range(epochs)):  # loop over the dataset multiple times\n",
    "    # randomly generate pair dataset\n",
    "    dataset = DatasetCon(train_sample,frame)\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size = 4, shuffle = True)\n",
    "    # Train on data\n",
    "    train_loss = train(data_loader,net,optimizer,criterion,device)\n",
    "    #print(train_loss)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
